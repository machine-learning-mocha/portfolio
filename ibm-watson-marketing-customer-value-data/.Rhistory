origin = "1899-12-30"), "X%m.%d.%y")
names(b)[-c(1, 2, 3, 4)]
b <- df[df$Country.Region == 'Brazil', ]
(b)[-c(1, 2, 3, 4)]
plot((b)[-c(1, 2, 3, 4)])
c <- (b)[-c(1, 2, 3, 4)]
plot(c)
dev.off()
plot(c)
c <- (b)[-c(1, 2, 3, 4)]
plot(c)
graphics.off()
graphics.off()
dev.off()
graphics.off()
c <- (b)[-c(1, 2, 3, 4)]
plot(c)
plot(c)
par(mar=c(1,1,1,1))
plot(c)
View(c)
plot(t(c))
plot(t(log10(c)))
exponential.model <- lm(log(Counts)~ Time)
exponential.model <- lm(log(c)~ Time)
c(1:10)
dim(c)
c(1:135)
dia <- c(1:135)
cc <- (b)[-c(1, 2, 3, 4)]
rm(list = ls())
df <- read.csv(url("https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_time_series/time_series_covid19_confirmed_global.csv"))
b <- df[df$Country.Region == 'Brazil', ]
names(b)[-c(1, 2, 3, 4)]
dev.off()
graphics.off()
casos <- (b)[-c(1, 2, 3, 4)]
dia <- c(1:135)
df <- structure(list(casos= casos, dias = dias))
df_f <- structure(list(casos = casos, dias = dia))
df_f <- structure(list(casos = casos, dias = dia), class = "data.frame")
df_f <- structure(list(casos = casos, dias = dia),
.Names = c("Casos", "Dia"), class = "data.frame")
df_f <- structure(list(casos = casos, dias = dia),
.Names = c("Casos", "Dia"), class = "data.frame")
View(df_f)
View(df_f)
View(df_f)
attach(df_f)
View(df_f)
df_f <- structure(list(casos = casos, dias = dia),
.Names = c("Casos", "Dia"), class = "data.frame",
row.names = dia)
attach(df_f)
View(df_f)
df_f <- structure(list(casos = casos, dias = dia),
.Names = c("Casos", "Dia"), class = "data.frame",
row.names = dia)
View(df_f)
df_f <- structure(list(casos = casos, dias = dia),
.Names = c("Casos", "Dia"), class = "data.frame",
row.names = c(1L))
View(df_f)
plot(df_f)
plot(t(df_f))
plot(t(log10(c)))
predictedCLV <- predict(new_fit)
source('D:/Fabio/projetos/portfolio/ibm-watson-marketing-customer-value-data/01-exploration.R', encoding = 'UTF-8')
#print actual CLV to compare it with above calculated predicted CLV.
print(insurncTrain$CustomerLifetimeValue[1:10])
#print actual CLV to compare it with above calculated predicted CLV.
print(insurncTrain$customer_lifetime_value[1:10])
residualsCLV <- residuals(new_fit)
print(residualsCLV[1:10])
predicatedTestData=predict(new_fit,insurncTest)
print(predicatedTestData[1:10])
InsuranceTrainData <- cbind(insurncTrain,predictedCLV,residualsCLV)
head(InsuranceTrainData)
ErrorRate <- abs((InsuranceTrainData$customer_lifetime_value - InsuranceTrainData$predictedCLV)/(InsuranceTrainData$customer_lifetime_value)*100)
print(ErrorRate[1:10])
InsuranceTrainData <- cbind(InsuranceTrainData, ErrorRate)
head(InsuranceTrainData)
mean(InsuranceTrainData$ErrorRate, na.rm = TRUE)
hist(ErrorRate, col = "blue")
boxplot(ErrorRate)
shapiro.test(residualsCLV[0:5000])
hist(residualsCLV,col = "green")
plot(new_fit, which=1, col=c("blue"))
cor(InsuranceTrainData)
# Variance Inflation Factors
car::vif(new_fit)
bptest(new_fit)
dwt(new_fit)
ErrorRate <- mean(abs((InsuranceTrainData$CustomerLifetimeValue - InsuranceTrainData$predictedCLV)/InsuranceTrainData$CustomerLifetimeValue) *100 )
print(ErrorRate)
ggplot(InsuranceTrainData, aes(x = MonthlyPremiumAuto, y = CustomerLifetimeValue)) +
geom_smooth(method = "lm", se = FALSE, color = "red") +     # regression line
geom_segment(aes(xend = MonthlyPremiumAuto, yend = predictedCLV), alpha = .2) +      # draw line from point to line
geom_point(aes(color = abs(residualsCLV), size = abs(residualsCLV))) +  # size of the points
scale_color_continuous(low = "green", high = "red") +             # colour of the points mapped to residual size - green smaller, red larger
guides(color = FALSE, size = FALSE) +                             # Size legend removed
geom_point(aes(y = predictedCLV), shape = 1) +
theme_bw()
ggplot(InsuranceTrainData, aes(x = monthly_premium_auto, y = customer_lifetime_value)) +
geom_smooth(method = "lm", se = FALSE, color = "red") +     # regression line
geom_segment(aes(xend = MonthlyPremiumAuto, yend = predictedCLV), alpha = .2) +      # draw line from point to line
geom_point(aes(color = abs(residualsCLV), size = abs(residualsCLV))) +  # size of the points
scale_color_continuous(low = "green", high = "red") +             # colour of the points mapped to residual size - green smaller, red larger
guides(color = FALSE, size = FALSE) +                             # Size legend removed
geom_point(aes(y = predictedCLV), shape = 1) +
theme_bw()
ggplot(InsuranceTrainData, aes(x = monthly_premium_auto, y = customer_lifetime_value)) +
geom_smooth(method = "lm", se = FALSE, color = "red") +     # regression line
geom_segment(aes(xend = monthly_premium_auto, yend = predictedCLV), alpha = .2) +      # draw line from point to line
geom_point(aes(color = abs(residualsCLV), size = abs(residualsCLV))) +  # size of the points
scale_color_continuous(low = "green", high = "red") +             # colour of the points mapped to residual size - green smaller, red larger
guides(color = FALSE, size = FALSE) +                             # Size legend removed
geom_point(aes(y = predictedCLV), shape = 1) +
theme_bw()
install.packages(c("neuralnet", "NeuralNetTools", "quantmod", "DMwR", "zoo", "forecast"))
library(neuralnet)
library(quantmod)
library(DMwR)
library(zoo)
rm(list = ls())
library(neuralnet)
library(quantmod)
library(DMwR)
library(zoo)
library(forecast)
getSymbols("IBM", src='yahoo',from = '2014-01-01', to = '2017-12-31')
names(IBM)<-c("open","high","low","close", "volume","ajusted")
dat = data.frame(Cl(IBM))
dat['closem1'] = Lag(Cl(IBM),1)
dat['closem2'] = Lag(Cl(IBM),2)
dat['closem3'] = Lag(Cl(IBM),3)
dat['closem4'] = Lag(Cl(IBM),4)
dat['closem5'] = Lag(Cl(IBM),5)
print(dat)
dat = na.fill(dat, "extend")
dat_scale = scale(dat)
nn = neuralnet(close  ~ closem1 + closem2 + closem3 + closem4 + closem5, data=dat_scale, hidden=c(2,3),threshold =1,stepmax= 1000)
print(nn)
plot(nn)
nn = neuralnet(close  ~ closem1 + closem2 + closem3 + closem4 + closem5, data=dat_scale,
hidden=c(7,4, 2),threshold =1,stepmax= 1000)
print(nn)
plot(nn)
nn = neuralnet(close  ~ closem1 + closem2 + closem3 + closem4 + closem5, data=dat_scale,
hidden=c(17, 14, 13, 3),threshold =1,stepmax= 1000)
print(nn)
plot(nn)
prev = predict(nn,dat_scale )
prev = unscale(prev,dat_scale)
print(prev)
plot(as.vector( Cl(IBM))  , type='l')
lines(prev,col='red')
accuracy(as.vector(prev),Cl(IBM))
getSymbols("PETR4.SA", src='yahoo',from = '2020-01-01', to = '2020-06-24')
getSymbols("PETR4", src='yahoo',from = '2020-01-01', to = '2020-06-24')
getSymbols("PETR4.SA", src='yahoo',from = '2020-01-01', to = '2020-06-24')
getSymbols("PETR4.SA", src='yahoo',from = '2020-01-01', to = '2020-06-24')
IBM = na.fill(IBM, "extend")
names(IBM)<-c("open","high","low","close", "volume","ajusted")
dat = data.frame(Cl(IBM))
dat['closem1'] = Lag(Cl(IBM),1)
dat['closem2'] = Lag(Cl(IBM),2)
dat['closem3'] = Lag(Cl(IBM),3)
dat['closem4'] = Lag(Cl(IBM),4)
dat['closem5'] = Lag(Cl(IBM),5)
print(dat)
dat = na.fill(dat, "extend")
dat_scale = scale(dat)
nn = neuralnet(close  ~ closem1 + closem2 + closem3 + closem4 + closem5, data=dat_scale,
hidden=c(17, 14, 13, 3),threshold =1,stepmax= 1000)
print(nn)
plot(nn)
prev = predict(nn,dat_scale )
prev = unscale(prev,dat_scale)
print(prev)
plot(as.vector( Cl(IBM))  , type='l')
lines(prev,col='red')
accuracy(as.vector(prev),Cl(IBM))
getSymbols("PETR4.SA", src='yahoo',from = '2020-01-01', to = '2020-06-24')
IBM = na.fill(IBM, "extend")
names(IBM)<-c("open","high","low","close", "volume","ajusted")
dat = data.frame(Cl(IBM))
dat['closem1'] = Lag(Cl(IBM),1)
dat['closem2'] = Lag(Cl(IBM),2)
dat['closem3'] = Lag(Cl(IBM),3)
dat['closem4'] = Lag(Cl(IBM),4)
dat['closem5'] = Lag(Cl(IBM),5)
print(dat)
dat = na.fill(dat, "extend")
dat_scale = scale(dat)
nn = neuralnet(close  ~ closem1 + closem2 + closem3 + closem4 + closem5, data=dat_scale,
hidden=c(17, 14, 13, 3),threshold =1,stepmax= 1000)
rm(list = ls())
getSymbols("PETR4.SA", src='yahoo',from = '2020-01-01', to = '2020-06-24')
getSymbols("PETR4.SA", src='yahoo',from = '2020-01-01', to = '2020-06-24')
stock = PETR4.SA
stock = na.fill(stock, "extend")
names(stock)<-c("open","high","low","close", "volume","ajusted")
dat = data.frame(Cl(stock))
dat['closem1'] = Lag(Cl(stock),1)
dat['closem2'] = Lag(Cl(stock),2)
dat['closem3'] = Lag(Cl(stock),3)
dat['closem4'] = Lag(Cl(stock),4)
dat['closem5'] = Lag(Cl(stock),5)
print(dat)
dat = na.fill(dat, "extend")
dat_scale = scale(dat)
nn = neuralnet(close  ~ closem1 + closem2 + closem3 + closem4 + closem5, data=dat_scale,
hidden=c(17, 14, 13, 3),threshold =1,stepmax= 1000)
print(nn)
plot(nn)
prev = predict(nn,dat_scale )
prev = unscale(prev,dat_scale)
print(prev)
plot(as.vector( Cl(IBM))  , type='l')
plot(as.vector( Cl(stock))  , type='l')
lines(prev,col='red')
accuracy(as.vector(prev),Cl(stock))
nn = neuralnet(close  ~ closem1 + closem2 + closem3 + closem4 + closem5, data=dat_scale,
hidden=c(7, 4, 3, 2),threshold =1,stepmax= 1000)
print(nn)
plot(nn)
print(nn)
prev = predict(nn,dat_scale )
prev = unscale(prev,dat_scale)
print(prev)
plot(as.vector( Cl(stock))  , type='l')
lines(prev,col='red')
nn = neuralnet(close  ~ closem1 + closem2 + closem3 + closem4 + closem5, data=dat_scale,
hidden=c(5, 3,),threshold =1,stepmax= 1000)
print(nn)
prev = predict(nn,dat_scale )
prev = unscale(prev,dat_scale)
print(prev)
plot(as.vector( Cl(stock))  , type='l')
lines(prev,col='red')
accuracy(as.vector(prev),Cl(stock))
nn = neuralnet(close  ~ closem1 + closem2 + closem3 + closem4 + closem5, data=dat_scale,
hidden=c(50, 30, 20, 10, 7, 5, 3, 2),threshold =1,stepmax= 1000)
print(nn)
prev = predict(nn,dat_scale )
prev = unscale(prev,dat_scale)
print(prev)
plot(as.vector( Cl(stock))  , type='l')
lines(prev,col='red')
dat_scale = scale(dat)
nn = neuralnet(close  ~ closem1 + closem2 + closem3 + closem4 + closem5, data=dat_scale,
hidden=c(50, 30, 20, 10, 7, 5, 3, 2),threshold =1,stepmax= 1000)
print(nn)
prev = predict(nn,dat_scale )
prev = unscale(prev,dat_scale)
print(prev)
plot(as.vector( Cl(stock))  , type='l')
lines(prev,col='red')
accuracy(as.vector(prev),Cl(stock))
nn = neuralnet(close  ~ closem1 + closem2 + closem3 + closem4 + closem5, data=dat_scale,
hidden=c(5, 4, 3, 2, 7, 5, 3, 2),threshold =1,stepmax= 1000)
print(nn)
prev = predict(nn,dat_scale )
prev = unscale(prev,dat_scale)
print(prev)
plot(as.vector( Cl(stock))  , type='l')
lines(prev,col='red')
nn = neuralnet(close  ~ closem1 + closem2 + closem3 + closem4 + closem5, data=dat_scale,
hidden=c(5, 4, 3, 2),threshold =1,stepmax= 1000)
print(nn)
prev = predict(nn,dat_scale )
prev = unscale(prev,dat_scale)
print(prev)
plot(as.vector( Cl(stock))  , type='l')
lines(prev,col='red')
accuracy(as.vector(prev),Cl(stock))
nn = neuralnet(close  ~ closem1 + closem2 + closem3 + closem4 + closem5, data=dat_scale,
hidden=c(5, 3, 2),threshold =1,stepmax= 1000)
print(nn)
prev = predict(nn,dat_scale )
prev = unscale(prev,dat_scale)
print(prev)
plot(as.vector( Cl(stock))  , type='l')
lines(prev,col='red')
accuracy(as.vector(prev),Cl(stock))
nn = neuralnet(close  ~ ., data=dat_scale,
hidden=c(5, 3, 2),threshold =1,stepmax= 1000)
print(nn)
prev = predict(nn,dat_scale )
prev = unscale(prev,dat_scale)
print(prev)
plot(as.vector( Cl(stock))  , type='l')
lines(prev,col='red')
accuracy(as.vector(prev),Cl(stock))
source('~/.active-rstudio-document')
rm(list = ls())
library(neuralnet)
library(quantmod)
library(DMwR)
library(zoo)
library(forecast)
getSymbols("PETR4.SA", src='yahoo',from = '2020-01-01', to = '2020-06-24')
stock = PETR4.SA
stock = na.fill(stock, "extend")
names(stock)<-c("open","high","low","close", "volume","ajusted")
dat = data.frame(Cl(stock))
dat['closem1'] = Lag(Cl(stock),1)
dat['closem2'] = Lag(Cl(stock),2)
dat['closem3'] = Lag(Cl(stock),3)
dat['closem4'] = Lag(Cl(stock),4)
dat['closem5'] = Lag(Cl(stock),5)
dat['closem6'] = Lag(Cl(stock),6)
dat['closem7'] = Lag(Cl(stock),7)
dat['closem8'] = Lag(Cl(stock),8)
dat['closem9'] = Lag(Cl(stock),9)
dat['closem10'] = Lag(Cl(stock),10)
dat['closem11'] = Lag(Cl(stock),11)
print(dat)
dat = na.fill(dat, "extend")
dat_scale = scale(dat)
nn = neuralnet(close  ~ ., data=dat_scale,
hidden=c(5, 3, 2),threshold =1,stepmax= 1000)
print(nn)
prev = predict(nn,dat_scale )
prev = unscale(prev,dat_scale)
print(prev)
plot(as.vector( Cl(stock))  , type='l')
lines(prev,col='red')
accuracy(as.vector(prev),Cl(stock))
nn = neuralnet(close  ~ ., data=dat_scale,
hidden=c(11, 10, 5, 3),threshold =1,stepmax= 1000)
print(nn)
prev = predict(nn,dat_scale )
prev = unscale(prev,dat_scale)
print(prev)
plot(as.vector( Cl(stock))  , type='l')
lines(prev,col='red')
nn = neuralnet(close  ~ ., data=dat_scale,
hidden=c(11, 10, 9,8, 7, 6, 5, 4, 3, 2),threshold = 1,stepmax= 2000)
print(nn)
prev = predict(nn,dat_scale )
prev = unscale(prev,dat_scale)
print(prev)
plot(as.vector( Cl(stock))  , type='l')
lines(prev,col='red')
nn = neuralnet(close  ~ ., data=dat_scale,
hidden=c(10, 9, 8, 7, 6, 5, 4, 3, 2),threshold = 1,stepmax= 2000)
print(nn)
prev = predict(nn,dat_scale )
prev = unscale(prev,dat_scale)
print(prev)
plot(as.vector( Cl(stock))  , type='l')
lines(prev,col='red')
nn = neuralnet(close  ~ ., data=dat_scale,
hidden=c(9, 4, 3, 2),threshold = 1,stepmax= 2000)
nn = neuralnet(close  ~ ., data=dat_scale,
hidden=c(2, 3),threshold = 1,stepmax= 2000)
print(nn)
prev = predict(nn,dat_scale )
prev = unscale(prev,dat_scale)
print(prev)
plot(as.vector( Cl(stock))  , type='l')
lines(prev,col='red')
accuracy(as.vector(prev),Cl(stock))
nn = neuralnet(close  ~ ., data=dat_scale,
hidden=c(2, 3, 15),threshold = 1,stepmax= 2000)
print(nn)
prev = predict(nn,dat_scale )
prev = unscale(prev,dat_scale)
print(prev)
plot(as.vector( Cl(stock))  , type='l')
lines(prev,col='red')
nn = neuralnet(close  ~ ., data=dat_scale,
hidden=c(2, 3, 15, 25),threshold = 1,stepmax= 2000)
print(nn)
prev = predict(nn,dat_scale )
prev = unscale(prev,dat_scale)
print(prev)
plot(as.vector( Cl(stock))  , type='l')
lines(prev,col='red')
accuracy(as.vector(prev),Cl(stock))
plot(as.vector( Cl(stock))  , type='l')
lines(prev,col='red')
nn = neuralnet(close  ~ ., data=dat_scale,
hidden=c(15, 25),threshold = 1,stepmax= 2000)
print(nn)
prev = predict(nn,dat_scale )
prev = unscale(prev,dat_scale)
print(prev)
plot(as.vector( Cl(stock))  , type='l')
lines(prev,col='red')
nn = neuralnet(close  ~ ., data=dat_scale,
hidden=c(15, 25),threshold = .8,stepmax= 2000)
print(nn)
prev = predict(nn,dat_scale )
prev = unscale(prev,dat_scale)
print(prev)
plot(as.vector( Cl(stock))  , type='l')
lines(prev,col='red')
nn = neuralnet(close  ~ ., data=dat_scale,
hidden=c(15, 50),threshold = .8,stepmax= 2000)
#print(nn)
#plot(nn)
prev = predict(nn,dat_scale )
prev = unscale(prev,dat_scale)
plot(as.vector( Cl(stock))  , type='l')
lines(prev,col='red')
nn = neuralnet(close  ~ ., data=dat_scale,
hidden=c(15, 50),threshold = .66,stepmax= 2000)
#print(nn)
#plot(nn)
prev = predict(nn,dat_scale )
prev = unscale(prev,dat_scale)
plot(as.vector( Cl(stock))  , type='l')
lines(prev,col='red')
accuracy(as.vector(prev),Cl(stock))
nn = neuralnet(close  ~ ., data=dat_scale,
hidden=c(15, 50),threshold = .66,stepmax= 1000)
#print(nn)
#plot(nn)
prev = predict(nn,dat_scale )
prev = unscale(prev,dat_scale)
plot(as.vector( Cl(stock))  , type='l')
lines(prev,col='red')
accuracy(as.vector(prev),Cl(stock))
nn = neuralnet(close  ~ ., data=dat_scale,
hidden=c(15, 50),threshold = .56,stepmax= 1000)
#print(nn)
#plot(nn)
prev = predict(nn,dat_scale )
prev = unscale(prev,dat_scale)
plot(as.vector( Cl(stock))  , type='l')
lines(prev,col='red')
accuracy(as.vector(prev),Cl(stock))
nn = neuralnet(close  ~ ., data=dat_scale,
hidden=c(3, 50),threshold = .56,stepmax= 1000)
#print(nn)
#plot(nn)
prev = predict(nn,dat_scale )
prev = unscale(prev,dat_scale)
plot(as.vector( Cl(stock))  , type='l')
lines(prev,col='red')
accuracy(as.vector(prev),Cl(stock))
nn = neuralnet(close  ~ ., data=dat_scale,
hidden=c(3, 55),threshold = .56,stepmax= 1000)
#print(nn)
#plot(nn)
prev = predict(nn,dat_scale )
prev = unscale(prev,dat_scale)
plot(as.vector( Cl(stock))  , type='l')
lines(prev,col='red')
accuracy(as.vector(prev),Cl(stock))
install.packages("keras")
source('~/.active-rstudio-document')
n
library(keras)
library(tensorflow)
base_image_path = get_file('paris.jpg', 'https://i.imgur.com/aGBdQyK.jpg')
result_prefix = 'sky_dream'
# These are the names of the layers
# for which we try to maximize activation,
# as well as their weight in the final loss
# we try to maximize.
# You can tweak these setting to obtain new visual effects.
layer_settings = list(
'mixed4' = 1.0,
'mixed5' = 1.5,
'mixed6' = 2.0,
'mixed7' = 2.5
)
# Playing with these hyperparameters will also allow you to achieve new effects
step = 0.01  # Gradient ascent step size
num_octave = 3  # Number of scales at which to run gradient ascent
octave_scale = 1.4  # Size ratio between scales
iterations = 20  # Number of ascent steps per scale
max_loss = 15.
# This is our base image:
plot(magick::image_read(base_image_path))
install.packages("magick")
# This is our base image:
plot(magick::image_read(base_image_path))
rm(list = ls())
library(keras)
library(tensorflow)
base_image_path = get_file('paris.jpg', 'https://i.imgur.com/aGBdQyK.jpg')
result_prefix = 'sky_dream'
# These are the names of the layers
# for which we try to maximize activation,
# as well as their weight in the final loss
# we try to maximize.
# You can tweak these setting to obtain new visual effects.
layer_settings = list(
'mixed4' = 1.0,
'mixed5' = 1.5,
'mixed6' = 2.0,
'mixed7' = 2.5
)
# Playing with these hyperparameters will also allow you to achieve new effects
step = 0.01  # Gradient ascent step size
num_octave = 3  # Number of scales at which to run gradient ascent
octave_scale = 1.4  # Size ratio between scales
iterations = 20  # Number of ascent steps per scale
max_loss = 15.
# This is our base image:
plot(magick::image_read(base_image_path))
source('D:/Fabio/projetos/portfolio/deep-dream/deep-dream.R')
source('D:/Fabio/projetos/portfolio/deep-dream/deep-dream.R')
version
install.packages("installr")
library(installr)
updateR()
