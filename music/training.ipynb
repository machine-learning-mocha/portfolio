{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import nltk\n",
    "import string\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "tf.enable_eager_execution()\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "sess = tf.Session(config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import LSTM\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.utils import np_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords = nltk.corpus.stopwords.words('portuguese')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open('myfile2.txt', encoding='iso-8859-1')     # Reading a UTF-8 file; 'r' is omitted\n",
    "rows = f.readlines()\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "plain_text = ''\n",
    "for music in rows:\n",
    "    for m in music.split():\n",
    "        m = ''.join(p for p in m if p not in string.punctuation)\n",
    "        if m.lower() not in stopwords:\n",
    "            plain_text += m.lower()+' '"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53 unique characters\n"
     ]
    }
   ],
   "source": [
    "vocab = sorted(set(plain_text))\n",
    "print ('{} unique characters'.format(len(vocab)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "char2idx = {u:i for i, u in enumerate(vocab)}\n",
    "idx2char = np.array(vocab)\n",
    "\n",
    "text_as_int = np.array([char2idx[c] for c in plain_text])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  ' ' :   0,\n",
      "  '0' :   1,\n",
      "  '1' :   2,\n",
      "  '2' :   3,\n",
      "  '3' :   4,\n",
      "  '4' :   5,\n",
      "  '5' :   6,\n",
      "  '6' :   7,\n",
      "  '7' :   8,\n",
      "  '8' :   9,\n",
      "  '9' :  10,\n",
      "  'a' :  11,\n",
      "  'b' :  12,\n",
      "  'c' :  13,\n",
      "  'd' :  14,\n",
      "  'e' :  15,\n",
      "  'f' :  16,\n",
      "  'g' :  17,\n",
      "  'h' :  18,\n",
      "  'i' :  19,\n",
      "  ...\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print('{')\n",
    "for char,_ in zip(char2idx, range(20)):\n",
    "    print('  {:4s}: {:3d},'.format(repr(char), char2idx[char]))\n",
    "print('  ...\\n}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'nunca vou diz' ---- characters mapped to int ---- > [24 31 24 13 11  0 32 25 31  0 14 19 36]\n"
     ]
    }
   ],
   "source": [
    "print ('{} ---- characters mapped to int ---- > {}'.format(repr(plain_text[:13]), text_as_int[:13]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n\n",
      "u\n",
      "n\n",
      "c\n",
      "a\n"
     ]
    }
   ],
   "source": [
    "# The maximum length sentence we want for a single input in characters\n",
    "seq_length = 100\n",
    "examples_per_epoch = len(plain_text)//seq_length\n",
    "\n",
    "# Create training examples / targets\n",
    "char_dataset = tf.data.Dataset.from_tensor_slices(text_as_int)\n",
    "\n",
    "for i in char_dataset.take(5):\n",
    "  print(idx2char[i.numpy()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'nunca vou dizer realmente penso nunca vou dizer realmente sinto juro juro nunca vou dizer realmente p'\n",
      "'enso nunca vou dizer realmente sinto juro juro deus juro juro deus confio ninguém confio ninguém conf'\n",
      "'io ninguém 30 confio ninguém 32 dentes pai dia falou pra nunca mentisse esqueceu dizer verdade ha ha '\n",
      "'ha ha nunca vou dizer realmente penso nunca vou dizer realmente sinto juro juro juro juro nunca vou d'\n",
      "'izer realmente penso nunca vou dizer realmente sinto juro juro juro deus juro juro juro deus confio n'\n"
     ]
    }
   ],
   "source": [
    "sequences = char_dataset.batch(seq_length+1, drop_remainder=True)\n",
    "\n",
    "for item in sequences.take(5):\n",
    "  print(repr(''.join(idx2char[item.numpy()])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_input_target(chunk):\n",
    "    input_text = chunk[:-1]\n",
    "    target_text = chunk[1:]\n",
    "    return input_text, target_text\n",
    "\n",
    "dataset = sequences.map(split_input_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<DatasetV1Adapter shapes: ((64, 100), (64, 100)), types: (tf.int32, tf.int32)>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Batch size\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "# Buffer size to shuffle the dataset\n",
    "# (TF data is designed to work with possibly infinite sequences,\n",
    "# so it doesn't attempt to shuffle the entire sequence in memory. Instead,\n",
    "# it maintains a buffer in which it shuffles elements).\n",
    "BUFFER_SIZE = 10000\n",
    "\n",
    "dataset = dataset.shuffle(BUFFER_SIZE).batch(BATCH_SIZE, drop_remainder=True)\n",
    "\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Length of the vocabulary in chars\n",
    "vocab_size = len(vocab)\n",
    "\n",
    "# The embedding dimension\n",
    "embedding_dim = 256\n",
    "\n",
    "# Number of RNN units\n",
    "rnn_units = 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "53"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensorflow.python.keras.layers.cudnn_recurrent.CuDNNGRU"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.keras.layers.CuDNNGRU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "if tf.test.is_gpu_available():\n",
    "  rnn = tf.keras.layers.CuDNNGRU\n",
    "#else:\n",
    "#  import functools\n",
    "#  rnn = functools.partial(\n",
    "#    tf.keras.layers.GRU, recurrent_activation='sigmoid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(vocab_size, embedding_dim, rnn_units, batch_size):\n",
    "  model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Embedding(vocab_size, embedding_dim,\n",
    "                              batch_input_shape=[batch_size, None]),\n",
    "    tf.keras.layers.LSTM(rnn_units,\n",
    "                        return_sequences=True,\n",
    "                        stateful=True,\n",
    "                        recurrent_initializer='glorot_uniform'),\n",
    "    tf.keras.layers.Dense(vocab_size)\n",
    "  ])\n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = build_model(\n",
    "  vocab_size = len(vocab),\n",
    "  embedding_dim=embedding_dim,\n",
    "  rnn_units=rnn_units,\n",
    "  batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "53"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64, 100, 53) # (batch_size, sequence_length, vocab_size)\n"
     ]
    }
   ],
   "source": [
    "for input_example_batch, target_example_batch in dataset.take(1):\n",
    "  example_batch_predictions = model(input_example_batch)\n",
    "  print(example_batch_predictions.shape, \"# (batch_size, sequence_length, vocab_size)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<DatasetV1Adapter shapes: ((64, 100), (64, 100)), types: (tf.int32, tf.int32)>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.take(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (64, None, 256)           13568     \n",
      "_________________________________________________________________\n",
      "lstm (LSTM)                  (64, None, 512)           1574912   \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (64, None, 53)            27189     \n",
      "=================================================================\n",
      "Total params: 1,615,669\n",
      "Trainable params: 1,615,669\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampled_indices = tf.random.categorical(example_batch_predictions[0], num_samples=1)\n",
    "sampled_indices = tf.squeeze(sampled_indices,axis=-1).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([12, 26, 42, 46, 13, 29, 24,  2, 16, 32, 41,  1, 18, 31,  7, 49, 25,\n",
       "       49, 31, 25, 23, 28, 42, 47, 24, 10, 52,  3, 15, 50, 29, 25, 46, 23,\n",
       "       21, 15,  5, 39, 25, 38,  5, 44, 19, 35, 40, 37, 46, 12, 29,  1, 25,\n",
       "       14, 50, 39, 48, 13, 41, 17, 23, 41,  2, 52, 28, 49,  3, 48,  3, 23,\n",
       "       37,  6, 38, 29, 20, 36,  1, 21,  6, 10, 22, 50, 28, 41, 41, 35, 22,\n",
       "        8,  1, 25, 31, 51, 22,  7, 32,  3, 18, 19, 32, 14, 41, 20],\n",
       "      dtype=int64)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sampled_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: \n",
      " 'nada pra acertar errar mão sinto bem assim sinto bem aonde sinto bem assim sinto bem aonde vou nada '\n",
      "\n",
      "Next Char Predictions: \n",
      " 'bpäícsn1fvã0hu6ôoôuomräñn9ü2eõsoímke4áo´4éiyâ³íbs0odõáócãgmã1ürô2ó2m³5´sjz0k59lõrããyl70ouúl6v2hivdãj'\n"
     ]
    }
   ],
   "source": [
    "print(\"Input: \\n\", repr(\"\".join(idx2char[input_example_batch[0]])))\n",
    "print()\n",
    "print(\"Next Char Predictions: \\n\", repr(\"\".join(idx2char[sampled_indices ])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction shape:  (64, 100, 53)  # (batch_size, sequence_length, vocab_size)\n",
      "scalar_loss:       3.9705963\n"
     ]
    }
   ],
   "source": [
    "def loss(labels, logits):\n",
    "  return tf.keras.losses.sparse_categorical_crossentropy(labels, logits, from_logits=True)\n",
    "\n",
    "example_batch_loss  = loss(target_example_batch, example_batch_predictions)\n",
    "print(\"Prediction shape: \", example_batch_predictions.shape, \" # (batch_size, sequence_length, vocab_size)\")\n",
    "print(\"scalar_loss:      \", example_batch_loss.numpy().mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss=loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer = tf.train.AdamOptimizer(),\n",
    "    loss = loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Directory where the checkpoints will be saved\n",
    "checkpoint_dir = './training_checkpoints'\n",
    "# Name of the checkpoint files\n",
    "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt_{epoch}\")\n",
    "\n",
    "checkpoint_callback=tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=checkpoint_prefix,\n",
    "    save_weights_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS=50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "WARNING:tensorflow:From C:\\Users\\suzan\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\ops\\math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "19/19 [==============================] - 10s 542ms/step - loss: 3.1890\n",
      "Epoch 2/50\n",
      "19/19 [==============================] - 9s 453ms/step - loss: 2.8706\n",
      "Epoch 3/50\n",
      "19/19 [==============================] - 9s 457ms/step - loss: 2.7455\n",
      "Epoch 4/50\n",
      "19/19 [==============================] - 9s 453ms/step - loss: 2.5328\n",
      "Epoch 5/50\n",
      "19/19 [==============================] - 9s 454ms/step - loss: 2.3759\n",
      "Epoch 6/50\n",
      "19/19 [==============================] - 9s 452ms/step - loss: 2.2899\n",
      "Epoch 7/50\n",
      "19/19 [==============================] - 9s 453ms/step - loss: 2.2357\n",
      "Epoch 8/50\n",
      "19/19 [==============================] - 9s 454ms/step - loss: 2.1973\n",
      "Epoch 9/50\n",
      "19/19 [==============================] - 9s 451ms/step - loss: 2.1652\n",
      "Epoch 10/50\n",
      "19/19 [==============================] - 9s 450ms/step - loss: 2.1360\n",
      "Epoch 11/50\n",
      "19/19 [==============================] - 9s 450ms/step - loss: 2.1079\n",
      "Epoch 12/50\n",
      "19/19 [==============================] - 8s 447ms/step - loss: 2.0802\n",
      "Epoch 13/50\n",
      "19/19 [==============================] - 9s 449ms/step - loss: 2.0521\n",
      "Epoch 14/50\n",
      "19/19 [==============================] - 8s 446ms/step - loss: 2.0239\n",
      "Epoch 15/50\n",
      "19/19 [==============================] - 9s 447ms/step - loss: 1.9953\n",
      "Epoch 16/50\n",
      "19/19 [==============================] - 8s 446ms/step - loss: 1.9666\n",
      "Epoch 17/50\n",
      "19/19 [==============================] - 9s 448ms/step - loss: 1.9368\n",
      "Epoch 18/50\n",
      "19/19 [==============================] - 8s 445ms/step - loss: 1.9063\n",
      "Epoch 19/50\n",
      "19/19 [==============================] - 9s 451ms/step - loss: 1.8753\n",
      "Epoch 20/50\n",
      "19/19 [==============================] - 8s 446ms/step - loss: 1.8439\n",
      "Epoch 21/50\n",
      "19/19 [==============================] - 8s 446ms/step - loss: 1.8131\n",
      "Epoch 22/50\n",
      "19/19 [==============================] - 8s 445ms/step - loss: 1.7828\n",
      "Epoch 23/50\n",
      "19/19 [==============================] - 8s 446ms/step - loss: 1.7512\n",
      "Epoch 24/50\n",
      "19/19 [==============================] - 8s 445ms/step - loss: 1.7196\n",
      "Epoch 25/50\n",
      "19/19 [==============================] - 8s 446ms/step - loss: 1.6888\n",
      "Epoch 26/50\n",
      "19/19 [==============================] - 8s 446ms/step - loss: 1.6591\n",
      "Epoch 27/50\n",
      "19/19 [==============================] - 9s 449ms/step - loss: 1.6305\n",
      "Epoch 28/50\n",
      "19/19 [==============================] - 9s 451ms/step - loss: 1.6011\n",
      "Epoch 29/50\n",
      "19/19 [==============================] - 9s 450ms/step - loss: 1.5696\n",
      "Epoch 30/50\n",
      "19/19 [==============================] - 9s 452ms/step - loss: 1.5399\n",
      "Epoch 31/50\n",
      "19/19 [==============================] - 9s 453ms/step - loss: 1.5130\n",
      "Epoch 32/50\n",
      "19/19 [==============================] - 9s 452ms/step - loss: 1.4838\n",
      "Epoch 33/50\n",
      "19/19 [==============================] - 9s 454ms/step - loss: 1.4567\n",
      "Epoch 34/50\n",
      "19/19 [==============================] - 9s 454ms/step - loss: 1.4300\n",
      "Epoch 35/50\n",
      "19/19 [==============================] - 9s 455ms/step - loss: 1.4041\n",
      "Epoch 36/50\n",
      "19/19 [==============================] - 9s 455ms/step - loss: 1.3756\n",
      "Epoch 37/50\n",
      "19/19 [==============================] - 9s 455ms/step - loss: 1.3459\n",
      "Epoch 38/50\n",
      "19/19 [==============================] - 9s 453ms/step - loss: 1.3156\n",
      "Epoch 39/50\n",
      "19/19 [==============================] - 9s 453ms/step - loss: 1.2899\n",
      "Epoch 40/50\n",
      "19/19 [==============================] - 9s 450ms/step - loss: 1.2663\n",
      "Epoch 41/50\n",
      "19/19 [==============================] - 9s 454ms/step - loss: 1.2414\n",
      "Epoch 42/50\n",
      "19/19 [==============================] - 9s 454ms/step - loss: 1.2142\n",
      "Epoch 43/50\n",
      "19/19 [==============================] - 9s 454ms/step - loss: 1.1874\n",
      "Epoch 44/50\n",
      "19/19 [==============================] - 9s 453ms/step - loss: 1.1578\n",
      "Epoch 45/50\n",
      "19/19 [==============================] - 9s 458ms/step - loss: 1.1305\n",
      "Epoch 46/50\n",
      "19/19 [==============================] - 9s 454ms/step - loss: 1.1033\n",
      "Epoch 47/50\n",
      "19/19 [==============================] - 9s 456ms/step - loss: 1.0719\n",
      "Epoch 48/50\n",
      "19/19 [==============================] - 9s 456ms/step - loss: 1.0409\n",
      "Epoch 49/50\n",
      "19/19 [==============================] - 9s 453ms/step - loss: 1.0136\n",
      "Epoch 50/50\n",
      "19/19 [==============================] - 9s 454ms/step - loss: 0.9894\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(dataset, epochs=EPOCHS, callbacks=[checkpoint_callback])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
